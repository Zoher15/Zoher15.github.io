---
layout: about
title: about
permalink: /
subtitle: <a href='https://cnets.indiana.edu/groups/nan'>NaN</a>&nbsp;&nbsp;<a href='https://osome.iu.edu/'>OSoMe</a>&nbsp;&nbsp;<a href='https://cnets.indiana.edu/'>CNetS</a>&nbsp;&nbsp;<a href='https://luddy.indiana.edu/index.html'>Luddy</a>&nbsp;&nbsp;<a href='https://www.iu.edu/'>IU</a>

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am currently pursuing a PhD in Computer Science at [Indiana University](https://www.iu.edu/)'s [Luddy School of Informatics, Computing and Engineering](https://luddy.indiana.edu/index.html), under the guidance of [Professor Filippo Menczer](https://cnets.indiana.edu/fil). I am actively involved in the [Observatory on Social Media](https://osome.iu.edu/) and the [NaN research group](https://cnets.indiana.edu/groups/nan). I also have the privilege to collaborate with [Professor Jisun An](https://jisun.me/) and [Professor Haewoon Kwak](https://haewoon.io/).

My research specializes in **Natural Language Processing (LLMs)**, **AI Alignment**, and **Reliable Machine Learning**. I focus on developing novel *steering* techniques to improve **safety, controllability**, and **interpretability** in Large Language Models and Vision-Language Models.

My current research centers on three key areas: **Zero-shot detection of AI-generated images** through task-aligned prompting of VLMs, supporting authenticity verification and content trust; **Community-aware content moderation**, using LLMs to interpret user history and apply nuanced, rule-grounded moderation at scale; and **Controlled reasoning in LLMs**, analyzing decoding dynamics to guide generation toward faithful, safe, and interpretable outputs.

This work contributes to the broader goals of AI alignment and safety, ensuring that advanced AI systems remain controllable, interpretable, and aligned with human values and community standards.

---

<div class="github-activity" style="text-align: center; margin: 2rem 0;">
  <h3>Recent GitHub Activity</h3>
  <p style="color: #666; font-size: 0.9em; margin-bottom: 1rem;">Contribution activity for the past year</p>
  <img src="https://ghchart.rshah.org/zoher15" alt="GitHub Contribution Chart" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
  <p style="color: #888; font-size: 0.8em; margin-top: 0.5rem;">Updated automatically â€¢ <a href="https://github.com/zoher15" target="_blank" style="color: #0366d6;">View on GitHub</a></p>
</div>

