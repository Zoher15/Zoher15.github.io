<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Review of Attention Models | Zoher Kachwala </title> <meta name="author" content="Zoher Kachwala"> <meta name="description" content="In-depth analysis of transformer architectures for PhD candidacy"> <meta name="keywords" content="AI alignment, AI safety, large language models, LLMs, multimodal AI, VLMs, natural language processing, reliable machine learning, AI-generated image detection, content moderation, prompt engineering, controllability, interpretability, steering techniques"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/face.jpg?513af27337a1e06a101da5b420edecb6"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://zoher15.github.io//projects/3_project/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Zoher</span> Kachwala </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/chocolate_workshop/">üç´ CNetS Chocolate Workshop </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Review of Attention Models</h1> <p class="post-description">In-depth analysis of transformer architectures for PhD candidacy</p> </header> <article> <h2 id="review-of-attention-models-transformer-architecture-analysis">Review of Attention Models: Transformer Architecture Analysis</h2> <p><strong>Duration:</strong> May 2021 ‚Äì August 2021<br> <strong>Institution:</strong> Indiana University<br> <strong>Purpose:</strong> PhD Candidacy Requirement</p> <h3 id="project-overview">Project Overview</h3> <p>This comprehensive research project involved conducting an in-depth analysis of transformer architectures, particularly BERT and GPT models, and their implications for modern Natural Language Processing. The review was completed as part of the PhD candidacy requirements and provided foundational knowledge for subsequent research in LLM reasoning and alignment.</p> <h3 id="key-focus-areas">Key Focus Areas</h3> <ul> <li> <strong>Transformer Architecture Deep Dive</strong>: Detailed analysis of the attention mechanism and its variants</li> <li> <strong>BERT Analysis</strong>: Comprehensive study of bidirectional encoder representations</li> <li> <strong>GPT Model Family</strong>: Examination of generative pre-trained transformers and their evolution</li> <li> <strong>Modern NLP Implications</strong>: Assessment of how these architectures transformed the field</li> <li> <strong>Future Research Directions</strong>: Identification of open challenges and opportunities</li> </ul> <h3 id="research-methodology">Research Methodology</h3> <p>The review employed systematic analysis across multiple dimensions:</p> <ol> <li> <strong>Architectural Analysis</strong>: Detailed examination of model components and design choices</li> <li> <strong>Performance Evaluation</strong>: Comparative analysis across various NLP tasks and benchmarks</li> <li> <strong>Computational Efficiency</strong>: Study of training and inference requirements</li> <li> <strong>Interpretability Assessment</strong>: Analysis of attention patterns and model behavior</li> <li> <strong>Scalability Considerations</strong>: Examination of how models perform at different scales</li> </ol> <h3 id="key-findings-and-insights">Key Findings and Insights</h3> <ul> <li> <strong>Attention Mechanism Evolution</strong>: Traced the development from basic attention to multi-head self-attention</li> <li> <strong>Bidirectional vs. Autoregressive</strong>: Comparative analysis of BERT‚Äôs bidirectional approach versus GPT‚Äôs autoregressive design</li> <li> <strong>Transfer Learning Impact</strong>: Assessment of how pre-trained transformers revolutionized NLP</li> <li> <strong>Scaling Laws</strong>: Early insights into the relationship between model size, data, and performance</li> <li> <strong>Emergent Capabilities</strong>: Identification of unexpected behaviors in large-scale models</li> </ul> <h3 id="technical-deep-dives">Technical Deep Dives</h3> <h4 id="attention-mechanisms">Attention Mechanisms</h4> <ul> <li> <strong>Self-Attention</strong>: Mathematical foundations and computational complexity</li> <li> <strong>Multi-Head Attention</strong>: Parallel processing and representation learning</li> <li> <strong>Positional Encoding</strong>: Methods for incorporating sequence order information</li> </ul> <h4 id="model-architectures">Model Architectures</h4> <ul> <li> <strong>BERT Variants</strong>: RoBERTa, ALBERT, DeBERTa, and architectural improvements</li> <li> <strong>GPT Evolution</strong>: From GPT-1 to GPT-3 and scaling considerations</li> <li> <strong>Hybrid Approaches</strong>: Models combining bidirectional and autoregressive elements</li> </ul> <h3 id="impact-on-subsequent-research">Impact on Subsequent Research</h3> <p>This foundational review directly informed my later research directions:</p> <ul> <li> <strong>LLM Reasoning</strong>: Understanding of how attention patterns relate to reasoning capabilities</li> <li> <strong>AI Alignment</strong>: Insights into model behavior and controllability challenges</li> <li> <strong>Interpretability</strong>: Foundation for developing steering techniques and understanding model internals</li> </ul> <h3 id="academic-contributions">Academic Contributions</h3> <ul> <li> <strong>Comprehensive Literature Survey</strong>: Systematic review of 100+ papers on transformer architectures</li> <li> <strong>Comparative Analysis Framework</strong>: Methodology for evaluating different architectural choices</li> <li> <strong>Future Research Roadmap</strong>: Identification of promising research directions that influenced subsequent work</li> <li> <strong>PhD Candidacy Advancement</strong>: Successfully completed candidacy requirements with distinction</li> </ul> <h3 id="technologies-and-tools-used">Technologies and Tools Used</h3> <ul> <li> <strong>Research Frameworks</strong>: PyTorch, TensorFlow for model analysis</li> <li> <strong>Evaluation Suites</strong>: GLUE, SuperGLUE, and custom benchmarks</li> <li> <strong>Visualization Tools</strong>: Attention visualization and model interpretation libraries</li> <li> <strong>Academic Resources</strong>: Comprehensive literature review across top-tier venues</li> </ul> <p>Every project has a beautiful feature showcase page. It‚Äôs easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1-480.webp 480w,/assets/img/1-800.webp 800w,/assets/img/1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3-480.webp 480w,/assets/img/3-800.webp 800w,/assets/img/3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5-480.webp 480w,/assets/img/5-800.webp 800w,/assets/img/5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5-480.webp 480w,/assets/img/5-800.webp 800w,/assets/img/5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then‚Ä¶ you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6-480.webp 480w,/assets/img/6-800.webp 800w,/assets/img/6-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11-480.webp 480w,/assets/img/11-800.webp 800w,/assets/img/11-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here‚Äôs the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Zoher Kachwala. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>