---
layout: page
title: Transformer Model Review
description: Conducted a literature review of various Transformer architectures (e.g., GPT, BERT) to survey their core mechanisms and capabilities.
img: assets/img/attention_models.jpg
importance: 3
category: work
related_publications: false
---

As part of my PhD candidacy requirements, I conducted a literature review of various Transformer architectures, including foundational models like GPT and BERT. The goal of this review was to survey their core mechanisms, understand their capabilities, and analyze their impact on the field of Natural Language Processing.
